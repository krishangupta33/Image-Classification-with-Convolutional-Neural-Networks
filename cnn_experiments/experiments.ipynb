{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load the image\n",
    "image_path = \"dog.jpeg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "grayscale_transform = transforms.Grayscale()\n",
    "grayscale_image = grayscale_transform(image)\n",
    "\n",
    "# Convert the grayscale image to a PyTorch tensor\n",
    "transform = transforms.ToTensor()\n",
    "image_tensor = transform(grayscale_image).unsqueeze(0)\n",
    "\n",
    "# Define the blur multiplier\n",
    "blur_multiplier = 1.1\n",
    "\n",
    "# Define a 5x5 Gaussian blur kernel\n",
    "gaussian_kernel = torch.tensor([[1., 4., 6., 4., 1.],\n",
    "                                [4., 16., 24., 16., 4.], \n",
    "                                [6., 24., 36., 24., 6.],\n",
    "                                [4., 16., 24., 16., 4.],\n",
    "                                [1., 4., 6., 4., 1.]]) / 256\n",
    "\n",
    "# Multiply the Gaussian kernel by the blur multiplier\n",
    "gaussian_kernel *= blur_multiplier\n",
    "\n",
    "# Add batch dimension and channel dimension to the kernel\n",
    "gaussian_kernel = gaussian_kernel.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Apply the Gaussian blur using conv2d\n",
    "output_tensor = F.conv2d(image_tensor, gaussian_kernel, padding=2)\n",
    "\n",
    "# Convert the output tensor back to a PIL image\n",
    "output_image = transforms.ToPILImage()(output_tensor.squeeze())\n",
    "\n",
    "# Save the blurred image\n",
    "output_image.save(\"blurred_dog_grayscale.jpeg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur for RGB all three channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load the image\n",
    "image_path = \"dog.jpeg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to a PyTorch tensor\n",
    "transform = transforms.ToTensor()\n",
    "image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "# Define the blur multipliers for each channel (R, G, B)\n",
    "blur_multipliers = [1, 1, 1]\n",
    "\n",
    "# Define a 5x5 Gaussian blur kernel\n",
    "gaussian_kernel = torch.tensor([[1., 4., 6., 4., 1.],\n",
    "                                [4., 16., 24., 16., 4.], \n",
    "                                [6., 24., 36., 24., 6.],\n",
    "                                [4., 16., 24., 16., 4.],\n",
    "                                [1., 4., 6., 4., 1.]]) / 256\n",
    "\n",
    "# Create an empty tensor to store the blurred image\n",
    "blurred_image_tensor = torch.zeros_like(image_tensor)\n",
    "\n",
    "# Apply Gaussian blur to each channel separately\n",
    "for c in range(3):\n",
    "    # Multiply the Gaussian kernel by the blur multiplier for the current channel\n",
    "    channel_kernel = gaussian_kernel * blur_multipliers[c]\n",
    "    \n",
    "    # Add batch dimension and channel dimension to the kernel\n",
    "    channel_kernel = channel_kernel.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Apply the Gaussian blur to the current channel using conv2d\n",
    "    blurred_image_tensor[:, c, :, :] = F.conv2d(image_tensor[:, c, :, :].unsqueeze(1), channel_kernel, padding=2).squeeze(1)\n",
    "\n",
    "# Convert the blurred image tensor back to a PIL image\n",
    "blurred_image = transforms.ToPILImage()(blurred_image_tensor.squeeze())\n",
    "\n",
    "# Save the blurred image\n",
    "blurred_image.save(\"blurred_dog_rgb.jpeg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load the image\n",
    "image_path = \"dog.jpeg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "grayscale_transform = transforms.Grayscale()\n",
    "grayscale_image = grayscale_transform(image)\n",
    "\n",
    "# Convert the grayscale image to a PyTorch tensor\n",
    "transform = transforms.ToTensor()\n",
    "image_tensor = transform(grayscale_image).unsqueeze(0)\n",
    "\n",
    "# Define the Sobel kernels for edge detection\n",
    "sobel_x = torch.tensor([[-1, 0, 1],\n",
    "                        [-2, 0, 2],\n",
    "                        [-1, 0, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "sobel_y = torch.tensor([[-1, -2, -1],\n",
    "                        [0, 0, 0],\n",
    "                        [1, 2, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Apply the Sobel kernels to the image using convolution\n",
    "edges_x = F.conv2d(image_tensor, sobel_x, padding=1)\n",
    "edges_y = F.conv2d(image_tensor, sobel_y, padding=1)\n",
    "\n",
    "# Compute the magnitude of the edges\n",
    "edges = torch.sqrt(edges_x**2 + edges_y**2)\n",
    "\n",
    "# Normalize the edge values to [0, 1]\n",
    "edges = (edges - edges.min()) / (edges.max() - edges.min())\n",
    "\n",
    "# Convert the edge tensor back to a PIL image\n",
    "edges_image = transforms.ToPILImage()(edges.squeeze())\n",
    "\n",
    "# Save the edges image\n",
    "edges_image.save(\"dog_edges.jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
